{
  "n_train": 5649,
  "n_test": 2422,
  "hallucination_rate_train": 0.5064613205877146,
  "hallucination_rate_test": 0.5066061106523534,
  "models": {
    "Perplexity (baseline)": {
      "features": [
        "perplexity_proxy"
      ],
      "auroc": 0.5030260559994271,
      "auroc_ci": [
        0.47982054457066997,
        0.5249608816644423
      ],
      "accuracy": 0.5119735755573905,
      "precision": 0.5127623369256948,
      "recall": 0.7367563162184189,
      "f1": 0.6046822742474917
    },
    "RAG faithfulness alone": {
      "features": [
        "rag_faithfulness"
      ],
      "auroc": 0.5339215626097602,
      "auroc_ci": [
        0.5119426511804507,
        0.5568979708776131
      ],
      "accuracy": 0.5189925681255161,
      "precision": 0.5224312590448625,
      "recall": 0.5884270578647107,
      "f1": 0.5534687619777693
    },
    "NLI entailment alone": {
      "features": [
        "nli_entailment"
      ],
      "auroc": 0.5052067668531951,
      "auroc_ci": [
        0.48210780402063214,
        0.5290144561466512
      ],
      "accuracy": 0.5037159372419489,
      "precision": 0.5085091899251192,
      "recall": 0.60880195599022,
      "f1": 0.5541543026706232
    },
    "SelfCheckGPT alone": {
      "features": [
        "selfcheck_gpt"
      ],
      "auroc": 0.4935854023658752,
      "auroc_ci": [
        0.46999625775407533,
        0.5168731349882176
      ],
      "accuracy": 0.5061932287365813,
      "precision": 0.5089337175792508,
      "recall": 0.7196414017929911,
      "f1": 0.5962187711006077
    },
    "GPT-4-Judge alone": {
      "features": [
        "gpt4_judge"
      ],
      "auroc": 0.556169246350421,
      "auroc_ci": [
        0.5330176605790502,
        0.5800510004497262
      ],
      "accuracy": 0.5470685383980182,
      "precision": 0.5394896719319563,
      "recall": 0.7237163814180929,
      "f1": 0.6181691611555865
    },
    "D_hat + coh_star + r_LZ (geometric only)": {
      "features": [
        "D_hat",
        "coh_star",
        "r_LZ"
      ],
      "auroc": 0.5198180410771587,
      "auroc_ci": [
        0.49698641594166776,
        0.5411884880143095
      ],
      "accuracy": 0.5148637489677952,
      "precision": 0.5147895335608647,
      "recall": 0.7375713121434393,
      "f1": 0.6063651591289783
    },
    "Perplexity + r_LZ": {
      "features": [
        "perplexity_proxy",
        "r_LZ"
      ],
      "auroc": 0.5033271611884618,
      "auroc_ci": [
        0.482427189908873,
        0.5267151131021374
      ],
      "accuracy": 0.5107349298100743,
      "precision": 0.5119318181818182,
      "recall": 0.7343113284433578,
      "f1": 0.6032808838299297
    },
    "Perplexity + D_hat + coh_star": {
      "features": [
        "perplexity_proxy",
        "D_hat",
        "coh_star"
      ],
      "auroc": 0.5098471285886248,
      "auroc_ci": [
        0.48672608310833465,
        0.5331855997709285
      ],
      "accuracy": 0.509083402146986,
      "precision": 0.5118159203980099,
      "recall": 0.6707416462917686,
      "f1": 0.580599647266314
    },
    "RAG + NLI": {
      "features": [
        "rag_faithfulness",
        "nli_entailment"
      ],
      "auroc": 0.5352842085161958,
      "auroc_ci": [
        0.5115191509782068,
        0.5568963652930272
      ],
      "accuracy": 0.5214698596201487,
      "precision": 0.5268562401263823,
      "recall": 0.5436022819885901,
      "f1": 0.5350982751704774
    },
    "RAG + SelfCheckGPT": {
      "features": [
        "rag_faithfulness",
        "selfcheck_gpt"
      ],
      "auroc": 0.5370100220628604,
      "auroc_ci": [
        0.5131051571731805,
        0.5584212675678306
      ],
      "accuracy": 0.5202312138728323,
      "precision": 0.5252133436772692,
      "recall": 0.5517522412387939,
      "f1": 0.5381558028616852
    },
    "NLI + SelfCheckGPT": {
      "features": [
        "nli_entailment",
        "selfcheck_gpt"
      ],
      "auroc": 0.5053533979192029,
      "auroc_ci": [
        0.4824357458442433,
        0.5291863689238158
      ],
      "accuracy": 0.5111478117258464,
      "precision": 0.513738019169329,
      "recall": 0.6552567237163814,
      "f1": 0.5759312320916905
    },
    "RAG + NLI + SelfCheckGPT": {
      "features": [
        "rag_faithfulness",
        "nli_entailment",
        "selfcheck_gpt"
      ],
      "auroc": 0.5373851247898572,
      "auroc_ci": [
        0.5136792552164486,
        0.5620050040926092
      ],
      "accuracy": 0.5227085053674649,
      "precision": 0.5278868813825609,
      "recall": 0.5476772616136919,
      "f1": 0.5376
    },
    "All semantic (RAG + NLI + SelfCheck + GPT4Judge)": {
      "features": [
        "rag_faithfulness",
        "nli_entailment",
        "selfcheck_gpt",
        "gpt4_judge"
      ],
      "auroc": 0.5483602895793052,
      "auroc_ci": [
        0.525023877320835,
        0.5701611450862858
      ],
      "accuracy": 0.5425268373245252,
      "precision": 0.5417543859649123,
      "recall": 0.6291768541157294,
      "f1": 0.5822021116138764
    },
    "Perplexity + RAG": {
      "features": [
        "perplexity_proxy",
        "rag_faithfulness"
      ],
      "auroc": 0.5343034853863389,
      "auroc_ci": [
        0.5110007528946966,
        0.555535870235133
      ],
      "accuracy": 0.5222956234516928,
      "precision": 0.526080476900149,
      "recall": 0.5753871230643847,
      "f1": 0.5496302063059556
    },
    "Geometric ensemble + RAG": {
      "features": [
        "D_hat",
        "coh_star",
        "r_LZ",
        "rag_faithfulness"
      ],
      "auroc": 0.5380572406761397,
      "auroc_ci": [
        0.5162140189262218,
        0.5606099762220146
      ],
      "accuracy": 0.523534269199009,
      "precision": 0.5262024407753051,
      "recall": 0.5973920130399348,
      "f1": 0.5595419847328245
    },
    "Geometric ensemble + NLI": {
      "features": [
        "D_hat",
        "coh_star",
        "r_LZ",
        "nli_entailment"
      ],
      "auroc": 0.5197048282541015,
      "auroc_ci": [
        0.4953566080656717,
        0.5428332674396473
      ],
      "accuracy": 0.5099091659785301,
      "precision": 0.5135869565217391,
      "recall": 0.6161369193154034,
      "f1": 0.5602074842534271
    },
    "Geometric ensemble + All semantic": {
      "features": [
        "D_hat",
        "coh_star",
        "r_LZ",
        "rag_faithfulness",
        "nli_entailment",
        "selfcheck_gpt",
        "gpt4_judge"
      ],
      "auroc": 0.553024180485792,
      "auroc_ci": [
        0.5332472502294191,
        0.5753377187147074
      ],
      "accuracy": 0.5379851362510322,
      "precision": 0.5381895332390382,
      "recall": 0.6202118989405053,
      "f1": 0.5762968572510413
    },
    "Full ensemble (All geometric + All semantic)": {
      "features": [
        "perplexity_proxy",
        "D_hat",
        "coh_star",
        "r_LZ",
        "lexical_diversity",
        "sentence_repetition",
        "length_tokens",
        "rag_faithfulness",
        "nli_entailment",
        "selfcheck_gpt",
        "gpt4_judge"
      ],
      "auroc": 0.5741615601545422,
      "auroc_ci": [
        0.5510747625765796,
        0.5973454931764799
      ],
      "accuracy": 0.5470685383980182,
      "precision": 0.545968882602546,
      "recall": 0.6291768541157294,
      "f1": 0.5846270352139341
    }
  },
  "mcnemar_tests": [
    {
      "comparison": "Perplexity (baseline) vs RAG faithfulness alone",
      "b": 583,
      "c": 600,
      "chi_squared": 0.21639898562975485,
      "p_value": 0.6417975161904571,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs NLI entailment alone",
      "b": 534,
      "c": 514,
      "chi_squared": 0.34446564885496184,
      "p_value": 0.5572628368465994,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs SelfCheckGPT alone",
      "b": 504,
      "c": 490,
      "chi_squared": 0.17002012072434608,
      "p_value": 0.680093926376758,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs GPT-4-Judge alone",
      "b": 518,
      "c": 603,
      "chi_squared": 6.294380017841213,
      "p_value": 0.012112137442476412,
      "significant": true
    },
    {
      "comparison": "Perplexity (baseline) vs D_hat + coh_star + r_LZ (geometric only)",
      "b": 487,
      "c": 494,
      "chi_squared": 0.03669724770642202,
      "p_value": 0.8480827592882225,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs Perplexity + r_LZ",
      "b": 10,
      "c": 7,
      "chi_squared": 0.23529411764705882,
      "p_value": 0.6276258050283593,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs Perplexity + D_hat + coh_star",
      "b": 335,
      "c": 328,
      "chi_squared": 0.05429864253393665,
      "p_value": 0.8157453387131137,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs RAG + NLI",
      "b": 591,
      "c": 614,
      "chi_squared": 0.4016597510373444,
      "p_value": 0.5262333348869614,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs RAG + SelfCheckGPT",
      "b": 619,
      "c": 639,
      "chi_squared": 0.28696343402225755,
      "p_value": 0.592173036675067,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs NLI + SelfCheckGPT",
      "b": 516,
      "c": 514,
      "chi_squared": 0.000970873786407767,
      "p_value": 0.975142858789852,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs RAG + NLI + SelfCheckGPT",
      "b": 607,
      "c": 633,
      "chi_squared": 0.5040322580645161,
      "p_value": 0.4777337208915725,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs All semantic (RAG + NLI + SelfCheck + GPT4Judge)",
      "b": 557,
      "c": 631,
      "chi_squared": 4.485690235690235,
      "p_value": 0.03417974167001858,
      "significant": true
    },
    {
      "comparison": "Perplexity (baseline) vs Perplexity + RAG",
      "b": 493,
      "c": 518,
      "chi_squared": 0.56973293768546,
      "p_value": 0.45036505934220883,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs Geometric ensemble + RAG",
      "b": 582,
      "c": 610,
      "chi_squared": 0.6115771812080537,
      "p_value": 0.43419459082721856,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs Geometric ensemble + NLI",
      "b": 544,
      "c": 539,
      "chi_squared": 0.014773776546629732,
      "p_value": 0.903257453334987,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs Geometric ensemble + All semantic",
      "b": 569,
      "c": 632,
      "chi_squared": 3.2006661115736885,
      "p_value": 0.07360828429769639,
      "significant": false
    },
    {
      "comparison": "Perplexity (baseline) vs Full ensemble (All geometric + All semantic)",
      "b": 484,
      "c": 569,
      "chi_squared": 6.700854700854701,
      "p_value": 0.009636670578809348,
      "significant": true
    }
  ]
}