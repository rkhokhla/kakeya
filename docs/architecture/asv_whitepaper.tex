\documentclass[11pt]{article}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{microtype}
\usepackage{amsmath,amssymb,amsthm,mathtools}
\usepackage{bbm}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}
\ewcommand{\coh}{\mathrm{coh}}
\newtheorem{remark}{Remark}

\title{Auditable Statistical Verification of LLM Outputs via\\ Geometric Signals and Conformal Guarantees}
\author{Roman Khokhla\\ \small Independent Researcher\\ \small \texttt{rkhokhla@gmail.com}}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
We present an \emph{auditable statistical verification} (ASV) layer for large language models (LLMs) that flags degenerate or unreliable generations using three lightweight geometric signals computed over token-embedding trajectories: (i) a multi-scale \emph{fractal slope} (robust Theil--Sen estimate over dyadic scales), (ii) \emph{directional coherence} (maximal projection concentration), and (iii) \emph{quantized-symbol complexity} (Lempel--Ziv compression on product-quantized embeddings). Rather than heuristic confidence aggregation, we calibrate a \emph{split-conformal classifier} on these signals to obtain distribution-free, finite-sample error control: for a miscoverage level $\delta$, the verifier's \textsc{ACCEPT} region attains coverage $\ge 1-\delta$ under exchangeability, without assuming independence among signals. We formalize a sampling bound for the coherence estimator via $\varepsilon$-nets on the sphere, specify reproducible \emph{proof-of-computation summaries} (PCS) with seed commitments and model/embedding attestation, and outline a public-data evaluation against contemporary hallucination benchmarks (TruthfulQA, FEVER, HaluEval, HalluLens). We replace earlier ``formal verification'' language with statistically sound, auditable guarantees anchored in standard results.
\end{abstract}

\section{Introduction}
LLMs produce fluent text but can hallucinate. Existing defenses (perplexity thresholds, self-consistency, or RAG heuristics) often lack explicit finite-sample guarantees and are difficult to audit. Conformal prediction provides distribution-free coverage for arbitrary base predictors via a simple calibration step, fitting naturally as a post-hoc wrapper around geometric signals computed from embedding trajectories. Our goal is a small, deterministic verifier that (i) emits compact, reproducible PCS artifacts and (ii) provides honest, distribution-free acceptance guarantees.

\paragraph{Contributions.}
\begin{itemize}
  \item \textbf{Signals.} Three cheap, model-agnostic signals on embedding paths: robust multi-scale slope $\hat D$, maximal directional coherence $\coh_\star$, and PQ$\to$LZ complexity $r_{\mathrm{LZ}}$.
  \item \textbf{Guarantees.} Split-conformal classification turns these scores into an \textsc{ACCEPT}/\textsc{ESCALATE}/\textsc{REJECT} policy with finite-sample miscoverage control---no independence assumption among signals.
  \item \textbf{Theory fixes.} We replace misapplied i.i.d.\ tail bounds with an $\varepsilon$-net/covering-number sampling bound for $\coh_\star$; we avoid interpreting raw float-byte compression as entropy by quantizing to a finite alphabet before universal coding.
  \item \textbf{Auditability.} PCS encapsulate seeds, codebook hashes, calibration digests, and decisions; logs are tamper-evident. We clarify that SOC~2/ISO~27001 are process attestations; PCS are auditable artifacts rather than formal proofs.
\end{itemize}

\section{Related Work}
\textbf{Conformal prediction.} Split/inductive conformal prediction delivers distribution-free coverage for sets produced by arbitrary scorers; extensions address abstention and some forms of distribution shift.\\
\textbf{Compression-based complexity.} Universal coding (Lempel--Ziv) and normalized compression distances relate compressibility to complexity for finite-alphabet sequences.\\
\textbf{Embedding quantization.} Product quantization (PQ) maps high-dimensional vectors to short discrete codes, enabling finite-alphabet complexity for trajectories.\\
\textbf{Hallucination benchmarks.} Public datasets such as TruthfulQA, FEVER, HaluEval, and HalluLens provide standardized evaluation for hallucination/faithfulness.

\section{Geometric Signals on Embedding Trajectories}
Let $E=(e_1,\dots,e_n)\in(\mathbb{R}^d)^n$ denote token embeddings.

\subsection{Multi-scale fractal slope $\hat D$ (robust Theil--Sen)}
Compute box-counts $N(s)$ for dyadic scales $s\in\{2,4,8,\dots\}$ on a bounding box of $E$. Regress $\log N$ on $\log s$ via \textbf{Theil--Sen} (median of pairwise slopes), yielding a robust slope proxy $\hat D$. We report bootstrap CIs and scale-sensitivity; we \emph{do not} assert finite-sample absolute bounds like $\hat D\le d$.

\subsection{Directional coherence $\coh(v)$ and $\coh_\star$}
For unit $v\in S^{d-1}$, project $p_i=\langle e_i,v\rangle$, bin into $B$ fixed bins, and define
\[
  \coh(v)=\max_{b\in[B]} \frac{1}{n}\sum_{i=1}^n \mathbbm{1}\{p_i\in \text{bin }b\},\qquad
  \coh_\star = \max_{v\in\mathcal{V}} \coh(v),
\]
approximating the sphere by a finite set $\mathcal{V}$ (random or deterministic). Loops and mode-locking typically yield high $\coh_\star$.

\subsection{Quantized-symbol complexity $r_{\mathrm{LZ}}$}
Product-quantize embeddings (e.g., $m$ subspaces with $b$ bits each) to obtain a finite-alphabet sequence $Z$. Define $r_{\mathrm{LZ}}$ as a (monotone) function of the LZ77 compression ratio or NCD of $Z$. This respects the finite-alphabet premise behind universal coding and avoids artifacts of compressing raw IEEE-754 bytes.

\section{From Scores to Guarantees: Split-Conformal Verification}
Let $s(x)\in\mathbb{R}^k$ collect the above signals and simple transforms (e.g., windowed variants). A base classifier produces a scalar \emph{nonconformity} score $\eta(x)$. On a held-out calibration set $\mathcal{C}$, compute the $(1-\delta)$ quantile $q_{1-\delta}$ of $\{\eta(x):x\in\mathcal{C}\}$. Define the \textsc{ACCEPT} region
\[
\mathcal{A}_\delta=\{x:\eta(x)\le q_{1-\delta}\}.
\]
Under exchangeability of calibration and test points, $\Pr\{x\text{ from the target class}\in\mathcal{A}_\delta\}\ge 1-\delta$ in finite samples. We adopt an \textsc{ESCALATE} state when ambiguity is high (e.g., near the quantile).

\paragraph{Non-exchangeability and drift.} Feedback loops and domain shift can break exchangeability. We mitigate via (i) periodic re-calibration, (ii) drift tests on summary statistics, and (iii) contamination-aware variants where appropriate.

\section{Theory Highlights}
\subsection{Robust slope: properties and reporting}
Theil--Sen provides a high-breakdown, outlier-resistant slope estimate on the $\log$--$\log$ curve $(\log s,\log N(s))$. We report bootstrap CIs and sensitivity to scale selection rather than asserting folklore variance claims.

\subsection{Directional coherence via $\varepsilon$-nets}
\begin{proposition}[Sampling bound for $\coh_\star$]\label{prop:coh}
Let $g(v)=\coh(v)$ on $S^{d-1}$ using fixed bins and a smoothed histogram so that $g$ is $L$-Lipschitz in the geodesic metric. Let $N(\varepsilon)$ be the covering number of $S^{d-1}$ by geodesic balls of radius $\varepsilon$. If $M\ge N(\varepsilon)\log(1/\delta)$ random directions are sampled uniformly, then with probability at least $1-\delta$,
\[
\max_{v\in\mathcal{V}_M} g(v) \ge \max_{u\in S^{d-1}} g(u) - L\,\varepsilon.
\]
\end{proposition}
\begin{proof}[Proof sketch]
A standard covering-number argument: with $M\ge N(\varepsilon)\log(1/\delta)$ i.i.d.\ samples, a union bound implies every ball in a fixed $\varepsilon$-net is hit with probability $\ge 1-\delta$. Lipschitz continuity then transfers the maximum from the net to the true maximum within $L\varepsilon$.
\end{proof}

\subsection{Finite-alphabet complexity}
For a discrete sequence $Z$ over a finite alphabet, Lempel--Ziv codes achieve rates approaching the entropy rate under broad conditions; thus compression ratio is a practical monotone of complexity for PQ-symbolized trajectories. We avoid interpreting compression of raw float bytes as semantic entropy.

\subsection{Conformal acceptance guarantee}
Given calibration set $\mathcal{C}$ and quantile $q_{1-\delta}$, split-conformal classification guarantees $\Pr\{\text{miscoverage}\}\le\delta$ without independence among features/scores; abstention is handled naturally by decision thresholds.

\section{Proof-of-Computation Summaries (PCS) and Auditability}
A PCS contains: (i) seed/RNG commitments; (ii) model and embedder attestations (name, version, SHA256); (iii) signal parameters (binning, PQ codebooks), (iv) per-signal values; (v) conformal calibration hashes and quantiles; (vi) decision. We append PCS to a tamper-evident log (e.g., WORM or immutable object store) and periodically anchor Merkle roots for batches. \emph{Note:} SOC~2 and ISO/IEC~27001 are process standards; PCS are auditable computational artifacts and do not constitute third-party attestations.

\section{Experimental Protocol (Public, Replicable)}
\paragraph{Benchmarks.} TruthfulQA (misconceptions), FEVER (claim verification), HaluEval (hallucination taxonomy), and HalluLens (intrinsic/extrinsic taxonomy).
\paragraph{Metrics.} We report \textsc{ACCEPT}/\textsc{ESCALATE}/\textsc{REJECT} confusion matrices, class priors, 95\% bootstrap CIs, ROC/AUPRC, and cost-sensitive trade-offs.
\paragraph{Baselines.} (a) ASV (ours, conformal), (b) perplexity thresholding, (c) entailment-based verifiers, (d) RAG faithfulness checks. We publish prompts, seeds, and PCS for all runs.

\subsection{Unified latency table (specification)}
\begin{center}
\begin{tabular}{lrrrr}
\toprule
Component & Median (ms) & p95 (ms) & Notes & Hardware \\
\midrule
PQ encoding ($n,d,m,b$) & & & $m$ subspaces, $b$ bits & \\
Fractal slope $\hat D$ & & & dyadic scales & \\
Directional coherence ($M,B$) & & & $M$ directions, $B$ bins & \\
LZ ratio $r_{\mathrm{LZ}}$ & & & window size & \\
Conformal scoring & & & model type & \\
\midrule
End-to-end & & & batch size & \\
\bottomrule
\end{tabular}
\end{center}

\section{Limitations and Threat Model}
Geometry flags structural degeneracy (loops, drift, mode collapse) rather than truth per se; combine with retrieval/entailment for factuality. Exchangeability may fail under heavy feedback; we mitigate via frequent re-calibration and drift tests. Adversaries can target signals; we recommend randomized challenge prompts, strict model/version attestation, and seed commitments; tamper-evident logging aids forensics.

\section{Conclusion}
Lightweight geometric signals, when calibrated with split-conformal prediction, yield honest, distribution-free acceptance guarantees and compact PCS artifacts suitable for audit. This reframing preserves engineering strengths (determinism, replayability) while grounding claims in standard theory.

\appendix
\section{PCS schema (abbreviated)}
\begin{itemize}
  \item \textbf{Model attestation:} model/embedding names, versions, SHA256 digests.
  \item \textbf{Seeds \& RNG:} global seed, direction/PQ/binning seeds.
  \item \textbf{Signals:} scales; $\hat D$ with bootstrap CI; $M,B$; $\coh_\star$; PQ bits; $r_{\mathrm{LZ}}$.
  \item \textbf{Conformal:} calibration hash, nonconformity definition, $q_{1-\delta}$, $\delta$.
  \item \textbf{Decision:} \textsc{ACCEPT}/\textsc{ESCALATE}/\textsc{REJECT} with rationale.
  \item \textbf{Audit anchors:} WORM location; batch Merkle root; timestamps.
\end{itemize}

\end{document}
